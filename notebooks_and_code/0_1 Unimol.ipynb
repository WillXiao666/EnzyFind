{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training additional machine learning models for the task of enzyme-substrate pair prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading and preprocessing data for model training and evaluation\n",
    "### 2. Training and validation machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/XWY/esp/ESP/notebooks_and_code\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "from os.path import join\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "#from hyperopt import fmin, tpe, hp, Trials, rand\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from hyperopt import fmin, tpe, hp, Trials, rand\n",
    "\n",
    "\n",
    "sys.path.append('.\\\\additional_code')\n",
    "#from data_preprocessing import *\n",
    "\n",
    "CURRENT_DIR = os.getcwd()\n",
    "print(CURRENT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading and preprocessing data for model training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_column_to_strings(df, column):\n",
    "    df[column] = [str(list(df[column][ind])) for ind in df.index]\n",
    "    return(df)\n",
    "\n",
    "def string_column_to_array(df, column):\n",
    "    df[column] = [np.array(eval(df[column][ind])) for ind in df.index]\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Loading data: \n",
    "Only keeping data points from the GO Annotation database with experimental evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/esp_38/lib/python3.8/site-packages/pandas/core/ops/array_ops.py:73: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = libops.scalar_compare(x.ravel(), y, op)\n",
      "/opt/anaconda3/envs/esp_38/lib/python3.8/site-packages/pandas/core/ops/array_ops.py:73: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = libops.scalar_compare(x.ravel(), y, op)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55878 13459\n",
      "52619 12614\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_pickle(join(CURRENT_DIR, \"..\" ,\"data\",\"splits\", \"df_train_with_ESM1b_ts_GNN.pkl\"))\n",
    "df_train = df_train.loc[df_train[\"ESM1b\"] != \"\"]\n",
    "df_train = df_train.loc[df_train[\"type\"] != \"engqvist\"]\n",
    "df_train = df_train.loc[df_train[\"GNN rep\"] != \"\"]\n",
    "df_train.reset_index(inplace = True, drop = True)\n",
    "\n",
    "df_test  = pd.read_pickle(join(CURRENT_DIR, \"..\" ,\"data\",\"splits\", \"df_test_with_ESM1b_ts_GNN.pkl\"))\n",
    "df_test = df_test.loc[df_test[\"ESM1b\"] != \"\"]\n",
    "df_test = df_test.loc[df_test[\"type\"] != \"engqvist\"]\n",
    "df_test = df_test.loc[df_test[\"GNN rep\"] != \"\"]\n",
    "df_test.reset_index(inplace = True, drop = True)\n",
    "print(len(df_train), len(df_test))\n",
    "\n",
    "df_unimol = pd.read_pickle(join(CURRENT_DIR, \"..\" ,\"data\",\"substrate_data\", \"df_unimol.pkl\"))\n",
    "\n",
    "df_merged = pd.merge(df_train, df_unimol[['substrate ID', 'unimol']], on='substrate ID', how='left')\n",
    "df_train = df_merged.loc[pd.notna(df_merged[\"unimol\"]) & (df_merged[\"unimol\"] != \"\")]\n",
    "\n",
    "df_merged = pd.merge(df_test, df_unimol[['substrate ID', 'unimol']], on='substrate ID', how='left')\n",
    "df_test = df_merged.loc[pd.notna(df_merged[\"unimol\"]) & (df_merged[\"unimol\"] != \"\")]\n",
    "print(len(df_train), len(df_test))\n",
    "df_train.reset_index(inplace = True, drop = True)\n",
    "df_test.reset_index(inplace = True, drop = True)\n",
    "\n",
    "df_train.keys()\n",
    "train_length, test_length = len(df_train), len(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Splitting training set into 5-folds for hyperparameter optimization:\n",
    "The 5 folds are created in such a way that the same enzyme does not occure in two different folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe(df, frac):\n",
    "    df1 = pd.DataFrame(columns = list(df.columns))\n",
    "    df2 = pd.DataFrame(columns = list(df.columns))\n",
    "    try:\n",
    "        df.drop(columns = [\"level_0\"], inplace = True)\n",
    "    except: \n",
    "        pass\n",
    "    df.reset_index(inplace = True)\n",
    "    \n",
    "    train_indices = []\n",
    "    test_indices = []\n",
    "    ind = 0\n",
    "    while len(train_indices) +len(test_indices) < len(df):\n",
    "        if ind not in train_indices and ind not in test_indices:\n",
    "            if ind % frac != 0:\n",
    "                n_old = len(train_indices)\n",
    "                train_indices.append(ind)\n",
    "                train_indices = list(set(train_indices))\n",
    "\n",
    "                while n_old != len(train_indices):\n",
    "                    n_old = len(train_indices)\n",
    "\n",
    "                    training_seqs= list(set(df[\"ESM1b\"].loc[train_indices]))\n",
    "\n",
    "                    train_indices = train_indices + (list(df.loc[df[\"ESM1b\"].isin(training_seqs)].index))\n",
    "                    train_indices = list(set(train_indices))\n",
    "                \n",
    "            else:\n",
    "                n_old = len(test_indices)\n",
    "                test_indices.append(ind)\n",
    "                test_indices = list(set(test_indices))\n",
    "\n",
    "                while n_old != len(test_indices):\n",
    "                    n_old = len(test_indices)\n",
    "\n",
    "                    testing_seqs= list(set(df[\"ESM1b\"].loc[test_indices]))\n",
    "\n",
    "                    test_indices = test_indices + (list(df.loc[df[\"ESM1b\"].isin(testing_seqs)].index))\n",
    "                    test_indices = list(set(test_indices))\n",
    "                \n",
    "        ind +=1\n",
    "    return(df.loc[train_indices], df.loc[test_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43497 10678\n",
      "32572 10925\n",
      "21656 10916\n",
      "10917 10739\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (5,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 34\u001b[0m\n\u001b[1;32m     30\u001b[0m             train_indices[i] \u001b[38;5;241m=\u001b[39m train_indices[i] \u001b[38;5;241m+\u001b[39m fold_indices[j]\n\u001b[1;32m     32\u001b[0m     test_indices[i] \u001b[38;5;241m=\u001b[39m fold_indices[i]\n\u001b[0;32m---> 34\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCURRENT_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m..\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msplits\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCV_train_indices.npy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m np\u001b[38;5;241m.\u001b[39msave(join(CURRENT_DIR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m ,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCV_test_indices.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m), test_indices)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36msave\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/esp_38/lib/python3.8/site-packages/numpy/lib/npyio.py:521\u001b[0m, in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    518\u001b[0m     file_ctx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m file_ctx \u001b[38;5;28;01mas\u001b[39;00m fid:\n\u001b[0;32m--> 521\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_array(fid, arr, allow_pickle\u001b[38;5;241m=\u001b[39mallow_pickle,\n\u001b[1;32m    523\u001b[0m                        pickle_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(fix_imports\u001b[38;5;241m=\u001b[39mfix_imports))\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (5,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "data_train2 = df_train.copy()\n",
    "data_train2 = array_column_to_strings(data_train2, column = \"ESM1b\")\n",
    "\n",
    "data_train2, df_fold = split_dataframe(df = data_train2, frac=5)\n",
    "indices_fold1 = list(df_fold[\"index\"])\n",
    "print(len(data_train2), len(indices_fold1))#\n",
    "\n",
    "data_train2, df_fold = split_dataframe(df = data_train2, frac=4)\n",
    "indices_fold2 = list(df_fold[\"index\"])\n",
    "print(len(data_train2), len(indices_fold2))\n",
    "\n",
    "data_train2, df_fold = split_dataframe(df = data_train2, frac=3)\n",
    "indices_fold3 = list(df_fold[\"index\"])\n",
    "print(len(data_train2), len(indices_fold3))\n",
    "\n",
    "data_train2, df_fold = split_dataframe(df = data_train2, frac=2)\n",
    "indices_fold4 = list(df_fold[\"index\"])\n",
    "indices_fold5 = list(data_train2[\"index\"])\n",
    "print(len(data_train2), len(indices_fold4))\n",
    "\n",
    "\n",
    "fold_indices = [indices_fold1, indices_fold2, indices_fold3, indices_fold4, indices_fold5]\n",
    "\n",
    "train_indices = [[], [], [], [], []]\n",
    "test_indices = [[], [], [], [], []]\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        if i != j:\n",
    "            train_indices[i] = train_indices[i] + fold_indices[j]\n",
    "            \n",
    "    test_indices[i] = fold_indices[i]\n",
    "    \n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\",\"splits\", \"CV_train_indices.npy\"), train_indices)\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\",\"splits\", \"CV_test_indices.npy\"), test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54175\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "52619"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_indices = list(np.load(join(CURRENT_DIR, \"..\" ,\"data\",\"splits\", \"CV_train_indices.npy\"),  allow_pickle=True))\n",
    "test_indices = list(np.load(join(CURRENT_DIR, \"..\" ,\"data\",\"splits\", \"CV_test_indices.npy\"),  allow_pickle=True))\n",
    "print(len(test_indices[0]) + len(train_indices[0]))\n",
    "train_indices = [ [idx for idx in row if idx < train_length] for row in train_indices]\n",
    "test_indices = [ [idx for idx in row if idx < train_length] for row in test_indices]\n",
    "len(train_indices[0])\n",
    "len(test_indices[0]) + len(train_indices[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating numpy arrays with input vectors and output variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_and_output_data(df):\n",
    "    X = ();\n",
    "    y = ();\n",
    "    \n",
    "    for ind in df.index:\n",
    "        emb = df[\"ESM1b_ts\"][ind]\n",
    "        ecfp = np.array(df[\"unimol\"][ind]).squeeze()\n",
    "                \n",
    "        X = X +(np.concatenate([ecfp, emb]), );\n",
    "        y = y + (df[\"Binding\"][ind], );\n",
    "\n",
    "    return(X,y)\n",
    "\n",
    "train_X, train_y =  create_input_and_output_data(df = df_train)\n",
    "test_X, test_y =  create_input_and_output_data(df = df_test)\n",
    "\n",
    "\n",
    "feature_names =  [\"ECFP_\" + str(i) for i in range(1024)]\n",
    "feature_names = feature_names + [\"ESM1b_ts_\" + str(i) for i in range(1280)]\n",
    "\n",
    "train_X = np.array(train_X)\n",
    "test_X  = np.array(test_X)\n",
    "\n",
    "train_y = np.array(train_y)\n",
    "test_y  = np.array(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of a single data point in train_X: 2048\n",
      "All data points in train_X have a consistent length.\n"
     ]
    }
   ],
   "source": [
    "# 检查 train_X 中第一个数据点的长度\n",
    "if 'train_X' in locals() and len(train_X) > 0:\n",
    "    first_sample_length = len(train_X[0])\n",
    "    print(f\"Length of a single data point in train_X: {first_sample_length}\")\n",
    "    \n",
    "    # (可选) 检查所有数据点的长度是否一致\n",
    "    all_lengths_consistent = all(len(sample) == first_sample_length for sample in train_X)\n",
    "    if all_lengths_consistent:\n",
    "        print(\"All data points in train_X have a consistent length.\")\n",
    "    else:\n",
    "        print(\"Warning: Data points in train_X have inconsistent lengths.\")\n",
    "else:\n",
    "    print(\"train_X is not defined or is empty. Please run the data creation cell first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.unique(train_y)\n",
    "weights = compute_class_weight(class_weight='balanced', classes=classes, y=train_y)\n",
    "class_weights = dict(zip(classes, weights))\n",
    "\n",
    "# normalize the features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_X)\n",
    "train_X = scaler.transform(train_X)\n",
    "test_X = scaler.transform(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training and validation machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (ii) Performing hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_neg_acc_logistic_regression(param):\n",
    "    param['solver'] = 'liblinear'\n",
    "    param['class_weight'] = class_weights\n",
    "    \n",
    "    loss = []\n",
    "    for i in range(5):\n",
    "        train_index, test_index  = train_indices[i], test_indices[i]        \n",
    "    \n",
    "        clf = LogisticRegression(max_iter=20, penalty = param[\"penalty\"],\n",
    "                                C = param[\"C\"], solver = param['solver'],\n",
    "                                class_weight= param[\"class_weight\"]\n",
    "                                ).fit(train_X[train_index], train_y[train_index])\n",
    "        y_valid_pred = np.round(clf.predict(train_X[test_index]))\n",
    "        validation_y = train_y[test_index]\n",
    "    \n",
    "        false_positive = 100*(1-np.mean(np.array(validation_y)[y_valid_pred == 1]))\n",
    "        false_negative = 100*(np.mean(np.array(validation_y)[y_valid_pred == 0]))\n",
    "        logging.info(\"False positive rate: \" + str(false_positive)+ \"; False negative rate: \" + str(false_negative))\n",
    "        loss.append(2*(false_negative**2) + false_positive**1.3)\n",
    "    return(np.mean(loss))\n",
    "\n",
    "#Defining search space for hyperparameter optimization\n",
    "space_logistic_regression = {'C': hp.choice('C', [1, 10, 100, 1000]),\n",
    "                            'penalty': hp.choice('penalty', ['l1', 'l2'])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing a random grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''trials = Trials()\n",
    "\n",
    "for i in range(1,10):\n",
    "    best = fmin(fn = cross_validation_neg_acc_logistic_regression, space = space_logistic_regression,\n",
    "                algo = rand.suggest, max_evals = i, trials = trials)\n",
    "    print(i)\n",
    "    print(trials.best_trial[\"result\"][\"loss\"])\n",
    "    print(trials.argmin)''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best set of hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'param = {\"C\" : 1,\\n        \"penalty\" : \"l2\"}\\n\\nparam[\\'solver\\'] = \\'liblinear\\'\\nparam[\\'class_weight\\'] = class_weights\\nnp.unique(train_y[test_indices[0]])'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''param = {\"C\" : 1,\n",
    "        \"penalty\" : \"l2\"}\n",
    "\n",
    "param['solver'] = 'liblinear'\n",
    "param['class_weight'] = class_weights\n",
    "np.unique(train_y[test_indices[0]])'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iii) Repeating 5-fold CV for best set of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'loss = []\\naccuracy = []\\nROC_AUC = []\\n\\nfor i in range(5):\\n    train_index, test_index  = train_indices[i], test_indices[i]\\n    clf = LogisticRegression(max_iter=250, penalty = param[\"penalty\"],\\n                                C = param[\"C\"], solver = param[\\'solver\\'],\\n                                class_weight= param[\"class_weight\"]\\n                                ).fit(train_X[train_index], train_y[train_index])\\n    y_valid_pred = np.round(clf.predict(train_X[test_index]))\\n    validation_y = train_y[test_index]\\n\\n    #calculate loss:\\n    false_positive = 100*(1-np.mean(np.array(validation_y)[y_valid_pred == 1]))\\n    false_negative = 100*(np.mean(np.array(validation_y)[y_valid_pred == 0]))\\n    logging.info(\"False positive rate: \" + str(false_positive)+ \"; False negative rate: \" + str(false_negative))\\n    loss.append(2*(false_negative**2) + false_positive**1.3)\\n    #calculate accuracy:\\n    accuracy.append(np.mean(y_valid_pred == np.array(validation_y)))\\n    #calculate ROC-AUC score:\\n    ROC_AUC.append(roc_auc_score(np.array(validation_y), clf.predict_proba(train_X[test_index])[:, 1]))\\n    \\nprint(\"Loss values: %s\" %loss) \\nprint(\"Accuracies: %s\" %accuracy)\\nprint(\"ROC-AUC scores: %s\" %ROC_AUC)\\n\\nnp.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"acc_CV_LR.npy\"), np.array(accuracy))\\nnp.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"loss_CV_LR.npy\"), np.array(loss))\\nnp.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"ROC_AUC_CV_LR.npy\"), np.array(ROC_AUC))'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''loss = []\n",
    "accuracy = []\n",
    "ROC_AUC = []\n",
    "\n",
    "for i in range(5):\n",
    "    train_index, test_index  = train_indices[i], test_indices[i]\n",
    "    clf = LogisticRegression(max_iter=250, penalty = param[\"penalty\"],\n",
    "                                C = param[\"C\"], solver = param['solver'],\n",
    "                                class_weight= param[\"class_weight\"]\n",
    "                                ).fit(train_X[train_index], train_y[train_index])\n",
    "    y_valid_pred = np.round(clf.predict(train_X[test_index]))\n",
    "    validation_y = train_y[test_index]\n",
    "\n",
    "    #calculate loss:\n",
    "    false_positive = 100*(1-np.mean(np.array(validation_y)[y_valid_pred == 1]))\n",
    "    false_negative = 100*(np.mean(np.array(validation_y)[y_valid_pred == 0]))\n",
    "    logging.info(\"False positive rate: \" + str(false_positive)+ \"; False negative rate: \" + str(false_negative))\n",
    "    loss.append(2*(false_negative**2) + false_positive**1.3)\n",
    "    #calculate accuracy:\n",
    "    accuracy.append(np.mean(y_valid_pred == np.array(validation_y)))\n",
    "    #calculate ROC-AUC score:\n",
    "    ROC_AUC.append(roc_auc_score(np.array(validation_y), clf.predict_proba(train_X[test_index])[:, 1]))\n",
    "    \n",
    "print(\"Loss values: %s\" %loss) \n",
    "print(\"Accuracies: %s\" %accuracy)\n",
    "print(\"ROC-AUC scores: %s\" %ROC_AUC)\n",
    "\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"acc_CV_LR.npy\"), np.array(accuracy))\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"loss_CV_LR.npy\"), np.array(loss))\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"ROC_AUC_CV_LR.npy\"), np.array(ROC_AUC))'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iv) 3. Training and validating the final model\n",
    "Training the model and validating it on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'clf = LogisticRegression(max_iter=250, penalty = param[\"penalty\"],\\n                                C = param[\"C\"], solver = param[\\'solver\\'],\\n                                class_weight= param[\"class_weight\"]\\n                                ).fit(train_X, train_y)\\ny_test_pred = np.round(clf.predict(test_X))\\nacc_test = np.mean(y_test_pred == np.array(test_y))\\nroc_auc = roc_auc_score(np.array(test_y), clf.predict_proba(test_X)[:, 1])\\nmcc = matthews_corrcoef(np.array(test_y), y_test_pred)\\n\\nprint(\"Accuracy on test set: %s, ROC-AUC score for test set: %s, MCC: %s\"  % (acc_test, roc_auc, mcc))'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''clf = LogisticRegression(max_iter=250, penalty = param[\"penalty\"],\n",
    "                                C = param[\"C\"], solver = param['solver'],\n",
    "                                class_weight= param[\"class_weight\"]\n",
    "                                ).fit(train_X, train_y)\n",
    "y_test_pred = np.round(clf.predict(test_X))\n",
    "acc_test = np.mean(y_test_pred == np.array(test_y))\n",
    "roc_auc = roc_auc_score(np.array(test_y), clf.predict_proba(test_X)[:, 1])\n",
    "mcc = matthews_corrcoef(np.array(test_y), y_test_pred)\n",
    "\n",
    "print(\"Accuracy on test set: %s, ROC-AUC score for test set: %s, MCC: %s\"  % (acc_test, roc_auc, mcc))'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_neg_acc_random_forest(param):\n",
    "    param['solver'] = 'liblinear'\n",
    "    param['class_weight'] = class_weights\n",
    "    \n",
    "    loss = []\n",
    "    for i in range(5):\n",
    "        train_index, test_index  = train_indices[i], test_indices[i]        \n",
    "    \n",
    "        clf = RandomForestClassifier(n_estimators = param[\"n_estimators\"],\n",
    "                                class_weight= param[\"class_weight\"]\n",
    "                                ).fit(train_X[train_index], train_y[train_index])\n",
    "        y_valid_pred = np.round(clf.predict(train_X[test_index]))\n",
    "        validation_y = train_y[test_index]\n",
    "    \n",
    "        false_positive = 100*(1-np.mean(np.array(validation_y)[y_valid_pred == 1]))\n",
    "        false_negative = 100*(np.mean(np.array(validation_y)[y_valid_pred == 0]))\n",
    "        logging.info(\"False positive rate: \" + str(false_positive)+ \"; False negative rate: \" + str(false_negative))\n",
    "        loss.append(2*(false_negative**2) + false_positive**1.3)\n",
    "    return(np.mean(loss))\n",
    "\n",
    "#Defining search space for hyperparameter optimization\n",
    "space_random_forest = {'n_estimators': hp.choice('n_estimators', [100, 200, 300])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing a random grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''trials = Trials()\n",
    "\n",
    "for i in range(1,10):\n",
    "    best = fmin(fn = cross_validation_neg_acc_random_forest, space = space_random_forest,\n",
    "                algo = rand.suggest, max_evals = i, trials = trials)\n",
    "    print(i)\n",
    "    print(trials.best_trial[\"result\"][\"loss\"])\n",
    "    print(trials.argmin)''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best set of hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\"n_estimators\" : 100}\n",
    "param['class_weight'] = class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss values: [300.3879056626604, 270.2830773331824, 271.7239055676095, 263.06719415399624, 262.7506355402403]\n",
      "Accuracies: [0.8867013372956909, 0.8934669636228656, 0.8927899686520376, 0.8950461796809404, 0.8922670191672174]\n",
      "ROC-AUC scores: [0.9327843302967208, 0.9342638103832339, 0.9373403389791934, 0.9374827542536525, 0.9315660871475806]\n"
     ]
    }
   ],
   "source": [
    "loss = []\n",
    "accuracy = []\n",
    "ROC_AUC = []\n",
    "\n",
    "for i in range(5):\n",
    "    train_index, test_index  = train_indices[i], test_indices[i]\n",
    "    clf = RandomForestClassifier(n_estimators = param[\"n_estimators\"],\n",
    "                                class_weight= param[\"class_weight\"]\n",
    "                                ).fit(train_X[train_index], train_y[train_index])\n",
    "    y_valid_pred = np.round(clf.predict(train_X[test_index]))\n",
    "    validation_y = train_y[test_index]\n",
    "\n",
    "    #calculate loss:\n",
    "    false_positive = 100*(1-np.mean(np.array(validation_y)[y_valid_pred == 1]))\n",
    "    false_negative = 100*(np.mean(np.array(validation_y)[y_valid_pred == 0]))\n",
    "    logging.info(\"False positive rate: \" + str(false_positive)+ \"; False negative rate: \" + str(false_negative))\n",
    "    loss.append(2*(false_negative**2) + false_positive**1.3)\n",
    "    #calculate accuracy:\n",
    "    accuracy.append(np.mean(y_valid_pred == np.array(validation_y)))\n",
    "    #calculate ROC-AUC score:\n",
    "    ROC_AUC.append(roc_auc_score(np.array(validation_y), clf.predict_proba(train_X[test_index])[:, 1]))\n",
    "    \n",
    "print(\"Loss values: %s\" %loss) \n",
    "print(\"Accuracies: %s\" %accuracy)\n",
    "print(\"ROC-AUC scores: %s\" %ROC_AUC)\n",
    "\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"acc_CV_random_forest.npy\"), np.array(accuracy))\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"loss_CV_random_forest.npy\"), np.array(loss))\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"ROC_AUC_CV_random_forest.npy\"), np.array(ROC_AUC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iv) 3. Training and validating the final model\n",
    "Training the model and validating it on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.9006459550907413, ROC-AUC score for test set: 0.9558865844969896, MCC: 0.7356092858899965\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators = param[\"n_estimators\"],\n",
    "                                class_weight= param[\"class_weight\"]\n",
    "                                ).fit(train_X, train_y)\n",
    "y_test_pred = np.round(clf.predict(test_X))\n",
    "acc_test = np.mean(y_test_pred == np.array(test_y))\n",
    "roc_auc = roc_auc_score(np.array(test_y), clf.predict_proba(test_X)[:, 1])\n",
    "mcc = matthews_corrcoef(np.array(test_y), y_test_pred)\n",
    "\n",
    "print(\"Accuracy on test set: %s, ROC-AUC score for test set: %s, MCC: %s\"  % (acc_test, roc_auc, mcc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esp_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
